\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{cite}

\title{Supplementary Materials\\
\large Multiscale Feature Extraction with Wavelet Scattering Transform for Remote Sensing Vegetation Classification via Machine Learning}

\author{Mattia Bruscia \and William Nardin \and Xiaoxu Guo \and Limin Sun \and Giulia Franchi}

\date{}

\begin{document}

\maketitle

\section{Synthetic Noise Conditions}

\textbf{Gaussian Noise (Additive White Gaussian Noise, AWGN)}

\textit{Characteristics:}
\begin{itemize}
    \item Type: additive, signal-independent
    \item Parameter: standard deviation $\sigma$
    \item Mathematical model: $I_{\text{noisy}}(x,y) = I(x,y) + N(0, \sigma^2)$
    \begin{itemize}
        \item $N(0, \sigma^2) \sim$ normal distribution with mean $0$ and variance $\sigma^2$
    \end{itemize}
\end{itemize}

\textit{Tested intensity levels:}
\begin{itemize}
    \item $\sigma = 10$ (low): \texttt{dataset\_rgb\_gaussian\_10} -- minimal thermal noise
    \item $\sigma = 30$ (moderate): \texttt{dataset\_rgb\_gaussian\_30} -- standard sensor degradation
    \item $\sigma = 50$ (high): \texttt{dataset\_rgb\_gaussian\_50} -- high electronic noise conditions
\end{itemize}

\textit{Rationale:} Simulates thermal noise from CCD/CMOS sensors, electronic interference from the acquisition circuit, and random disturbances during analog-to-digital conversion. It represents the most common noise type in photographic sensors.

\textbf{Poisson Noise (Shot Noise)}

\textit{Characteristics:}
\begin{itemize}
    \item Type: signal-dependent
    \item Parameter: scaling factor $\lambda$
    \item Mathematical model: $I_{\text{noisy}} \sim \mathrm{Poisson}(I \times \lambda) / \lambda$
    \begin{itemize}
        \item Noise variance is proportional to signal intensity
    \end{itemize}
\end{itemize}

\textit{Tested intensity levels:}
\begin{itemize}
    \item $\lambda = 40$ (low): \texttt{dataset\_rgb\_poisson\_40} -- adequate lighting conditions
    \item $\lambda = 60$ (moderate): \texttt{dataset\_rgb\_poisson\_60} -- reduced lighting
    \item $\lambda = 100$ (high): \texttt{dataset\_rgb\_poisson\_100} -- low-light conditions
\end{itemize}

\textit{Rationale:} Simulates shot noise caused by the quantized nature of photons. Particularly relevant in low-light conditions where photon count is limited. Poisson noise is intrinsic to the light detection process and cannot be completely eliminated.

\textbf{Salt \& Pepper Noise (Impulse Noise)}

\textit{Characteristics:}
\begin{itemize}
    \item Type: impulsive, binary
    \item Parameter: percentage of affected pixels ($p$)
    \item Mathematical model:
    \begin{itemize}
        \item With probability $p/2$: pixel $\rightarrow 0$ (pepper, black)
        \item With probability $p/2$: pixel $\rightarrow 255$ (salt, white)
        \item With probability $1-p$: pixel unchanged
    \end{itemize}
\end{itemize}

\textit{Tested intensity levels:}
\begin{itemize}
    \item $p = 5\%$ (low): \texttt{dataset\_rgb\_salt\_and\_pepper\_5} -- sporadic corruption
    \item $p = 15\%$ (moderate): \texttt{dataset\_rgb\_salt\_and\_pepper\_15} -- visible degradation
    \item $p = 25\%$ (high): \texttt{dataset\_rgb\_salt\_and\_pepper\_25} -- severe corruption
\end{itemize}

\textit{Rationale:} Simulates data transmission errors, dead/hot pixels in the sensor, impulsive electromagnetic interference, and memory errors during acquisition or storage. Common in wireless transmission systems and defective storage devices.

\textbf{Speckle Noise (Multiplicative Noise)}

\textit{Characteristics:}
\begin{itemize}
    \item Type: multiplicative (proportional to local intensity)
    \item Parameter: variance $\sigma^2_{\text{speckle}}$
    \item Mathematical model: $I_{\text{noisy}} = I + I \times N(0, \sigma^2_{\text{speckle}})$
    \begin{itemize}
        \item Noise is multiplied by pixel intensity
    \end{itemize}
\end{itemize}

\textit{Tested intensity levels:}
\begin{itemize}
    \item $\sigma^2 = 15$ (low): \texttt{dataset\_rgb\_speckle\_15} -- subtle speckle pattern
    \item $\sigma^2 = 35$ (moderate): \texttt{dataset\_rgb\_speckle\_35} -- visible granular texture
    \item $\sigma^2 = 55$ (high): \texttt{dataset\_rgb\_speckle\_55} -- significant texture degradation
\end{itemize}

\textit{Rationale:} Simulates speckle noise typical of coherent imaging systems such as Synthetic Aperture Radar (SAR), laser imaging, and ultrasound. Although less common in RGB optical imaging, it tests the robustness of methods to texture-dependent degradations that may occur under particular atmospheric conditions (fog, haze).

\textbf{Uniform Noise (Uniform Random Noise)}

\textit{Characteristics:}
\begin{itemize}
    \item Type: additive, uniform distribution
    \item Parameter: variation range $[-\mathrm{r}, +\mathrm{r}]$
    \item Mathematical model: $I_{\text{noisy}} = I + U(-\mathrm{r}, +\mathrm{r})$
    \begin{itemize}
        \item $U(-\mathrm{r}, +\mathrm{r}) \sim$ uniform distribution in the interval $[-\mathrm{r}, +\mathrm{r}]$
    \end{itemize}
\end{itemize}

\textit{Tested intensity levels:}
\begin{itemize}
    \item $r = 10$ (low): \texttt{dataset\_rgb\_uniform\_10} -- minimal variation
    \item $r = 25$ (moderate): \texttt{dataset\_rgb\_uniform\_25} -- visible fluctuation
    \item $r = 40$ (high): \texttt{dataset\_rgb\_uniform\_40} -- marked degradation
\end{itemize}

\textit{Rationale:} Simulates quantization errors, uniform sampling noise, temporal jitter during acquisition, and generic non-Gaussian disturbances. Represents a conservative noise model that does not favor any specific intensity.

\section{Mathematical Background: Wavelet Scattering Transform}

The Wavelet Scattering Transform (WST) represents a mathematically principled approach to multi-scale feature extraction that extends classical wavelet decompositions through cascaded convolutions with wavelet filters followed by modulus non-linearities. This architecture generates representations with provable stability and invariance properties, making it particularly suitable for texture analysis and pattern recognition under signal perturbations.

\subsection{Theoretical Foundation}

The construction begins with a family of complex-valued Morlet wavelets, defined as modulated Gaussian functions:

\[
\psi(t) = e^{-t^2/(2\sigma^2)} \cdot e^{i\omega_0 t}
\]

where $\sigma$ controls the spatial support and $\omega_0$ determines the central frequency. These wavelets are then scaled and rotated to form a filter bank $\{\psi_{\lambda}\}_{\lambda \in \Lambda}$, where each filter is parameterized by:

\[
\psi_{\lambda}(x) = 2^{-2j} \psi(2^{-j} r_{\theta} x)
\]

with $\lambda = (j, \theta)$, where $j \in \{0, 1, \ldots, J\}$ denotes the scale (corresponding to frequencies $2^{-j}$) and $\theta \in \{0, \pi/L, \ldots, (L-1)\pi/L\}$ represents the orientation angle. The parameter $J$ determines the maximum scale (capturing structures up to size $2^J$ pixels), while $L$ controls the angular resolution.

\subsection{Cascading Scattering Architecture}

The scattering transform is constructed recursively through iterated convolutions and complex modulus operations. For an input signal $x(u)$, the zero-th order coefficient captures the low-frequency average:

\[
S_0 x = x \star \varphi_J
\]

where $\varphi_J(u) = 2^{-2J} \varphi(2^{-J}u)$ is a low-pass averaging filter at scale $J$.

The first-order scattering coefficients are obtained by convolving with wavelets, applying the modulus non-linearity to ensure positivity and stability, and then averaging:

\[
S_1 x(\lambda_1) = |x \star \psi_{\lambda_1}| \star \varphi_J
\]

This operation decomposes the signal into directional components at different scales, where the modulus ensures translation invariance up to scale $2^J$.

Higher-order coefficients capture residual variations by iterating this process on the modulus of the first-order coefficients:

\[
S_2 x(\lambda_1, \lambda_2) = \big||x \star \psi_{\lambda_1}| \star \psi_{\lambda_2}\big| \star \varphi_J
\]

The second-order coefficients are particularly important for capturing texture regularity and local orientation patterns that are not accessible from first-order statistics alone.

The complete scattering representation is the concatenation:

\[
Sx = \{S_0 x, \{S_1 x(\lambda_1)\}_{\lambda_1}, \{S_2 x(\lambda_1, \lambda_2)\}_{\lambda_1, \lambda_2}\}
\]

For RGB images, this process is applied independently to each channel, and both mean and standard deviation statistics are computed over spatial locations, resulting in approximately 486 features per image in our implementation (using $J=3$ and $L=8$).

\subsection{Invariance and Stability Properties}

The theoretical appeal of WST derives from its provable invariance and stability guarantees.

\paragraph{Translation Invariance:} The averaging operator $\varphi_J$ provides translation invariance up to scale $2^J$. Formally, for any translation $\tau$:

\[
\|Sx(\cdot - \tau) - Sx(\cdot)\| \leq C \cdot 2^{-J} \|\nabla x\|
\]

where $C$ is a constant and $\nabla x$ denotes the spatial gradient. This ensures that small spatial shifts do not significantly alter the feature representation.

\paragraph{Deformation Stability:} More generally, the scattering transform is Lipschitz-continuous with respect to diffeomorphic deformations. For a smooth deformation field $\tau(u)$ and the deformed signal $x_{\tau}(u) = x(u - \tau(u))$:

\[
\|Sx_{\tau} - Sx\| \leq C \|x\| \sup_{u} \|\nabla \tau(u)\|
\]

This property ensures that moderate geometric distortions—such as those induced by viewpoint changes, object articulation, or sensor motion—produce bounded variations in the feature space.

\paragraph{Noise Stability:} Additive noise perturbations are also controlled. For $x_{\text{noisy}} = x + \epsilon$:

\[
\|S(x + \epsilon) - Sx\| \leq \|\epsilon\|
\]

The non-expansive nature of the scattering operator ensures that noise amplification does not occur across the cascaded layers, unlike in some learned representations where instability can arise.

\subsection{Comparison with Convolutional Neural Networks}

While CNNs and scattering networks share a similar architectural motif—alternating convolutions and non-linearities—they differ fundamentally in their construction and interpretation:

\begin{itemize}
    \item \textbf{Filter Learning:} CNN filters are learned from data through backpropagation, whereas WST filters are predefined Morlet wavelets with fixed geometric structure. This makes WST parameter-free but less adaptable to specific domains.
    \item \textbf{Theoretical Guarantees:} WST provides formal stability bounds, whereas CNN stability is typically empirical and task-dependent.
    \item \textbf{Data Requirements:} WST does not require training data for filter design, making it suitable for scenarios with limited labeled samples—a key advantage demonstrated in our data scarcity experiments.
    \item \textbf{Interpretability:} Each WST coefficient corresponds to a specific scale and orientation, facilitating physical interpretation. CNN activations, while powerful, are often less interpretable.
\end{itemize}

\subsection{Implementation Parameters in Kymatio}

Our implementation uses the Kymatio library, which provides GPU-accelerated scattering transforms. The key hyperparameters are:

\begin{itemize}
    \item \textbf{$J$ (maximum scale):} Set to 3, corresponding to maximum structure size $2^J = 8$ pixels. Larger $J$ captures coarser patterns but increases computational cost.
    \item \textbf{$Q$ (quality factor):} Number of wavelets per octave, set to 1. Higher $Q$ provides finer frequency resolution.
    \item \textbf{$L$ (number of orientations):} Set to 8, uniformly distributed over $[0, \pi)$. Captures directional texture information.
    \item \textbf{Order:} Maximum scattering order set to 2. Third-order coefficients are typically negligible for natural images.
\end{itemize}

The total number of scattering coefficients scales as $O(J \cdot L + J^2 \cdot L^2)$, which for our parameters yields approximately 81 coefficients per channel. Computing both mean and standard deviation over spatial positions doubles this count, resulting in $\sim162$ features per channel, or $\sim486$ features for RGB.

\section{Statistical Testing Framework: Detailed Methodology}

The comparative evaluation of feature extraction methods in this study relies on a rigorous statistical framework that combines normality assessment, non-parametric hypothesis testing, multiple comparison correction, and effect size quantification. This section provides complete methodological details and worked examples using data from our experiments.

\subsection{Normality Assessment: Shapiro-Wilk Test}

The Shapiro-Wilk test evaluates whether a sample of observations is drawn from a normal distribution. The test statistic $W$ is defined as:

\[
W = \frac{\left(\sum_{i=1}^{n} a_i x_{(i)}\right)^2}{\sum_{i=1}^{n} (x_i - \bar{x})^2}
\]

where $x_{(1)} \leq x_{(2)} \leq \cdots \leq x_{(n)}$ are the ordered sample values (order statistics), $\bar{x}$ is the sample mean, and $\{a_i\}_{i=1}^{n}$ are weights derived from the expected values, variances, and covariances of the order statistics of independent standard normal random variables.

The statistic $W$ lies in the interval $[0, 1]$, with values close to 1 indicating normality. The null hypothesis $H_0: \text{data} \sim \mathcal{N}(\mu, \sigma^2)$ is rejected for small values of $W$. Critical values and $p$-values are obtained via Monte Carlo simulation or tabulated distributions.

\paragraph{Application to Our Data:} For the pairwise deltas $\Delta_i = \text{Macro-F1}_{\text{WST}}(i) - \text{Macro-F1}_{\text{AdvStats}}(i)$ computed across 168 configurations:

\begin{itemize}
    \item Sample size: $n = 168$
    \item Computed $W = 0.9826$
    \item Corresponding $p$-value: $0.0213$
\end{itemize}

Since $p = 0.0213 < 0.05$, we reject the null hypothesis of normality at the $\alpha = 0.05$ level. The distribution exhibits slight skewness and heavier tails than a Gaussian, likely due to heterogeneity in noise effects across different experimental conditions. This violation of normality necessitates the use of non-parametric tests for subsequent inference.

Similarly, for the Hybrid vs.\ AdvStats comparison:

\begin{itemize}
    \item $n = 168$, $W = 0.9786$, $p = 0.0087 < 0.05$ $\Rightarrow$ reject normality
\end{itemize}

\subsection{Wilcoxon Signed-Rank Test: Step-by-Step Procedure}

The Wilcoxon signed-rank test is a non-parametric alternative to the paired $t$-test. It tests whether the median of paired differences differs significantly from zero, without assuming normality.

\paragraph{Algorithm:}

\begin{enumerate}
    \item \textbf{Compute differences:} For each configuration $i$, calculate $\Delta_i = \text{Method}_i - \text{Baseline}_i$
    \item \textbf{Remove zeros:} Exclude any $\Delta_i = 0$ (reduce sample size to $n'$)
    \item \textbf{Rank absolute values:} Assign ranks $1, 2, \ldots, n'$ to $|\Delta_1|, |\Delta_2|, \ldots, |\Delta_{n'}|$ in ascending order. Ties receive average ranks.
    \item \textbf{Attach signs:} Assign each rank the sign of the original $\Delta_i$
    \item \textbf{Compute rank sums:}
    \[
    R^+ = \sum_{\{\Delta_i > 0\}} \text{rank}(|\Delta_i|), \quad R^- = \sum_{\{\Delta_i < 0\}} \text{rank}(|\Delta_i|)
    \]
    \item \textbf{Test statistic:} $W = \min(R^+, R^-)$
    \item \textbf{$p$-value:} Under $H_0$ (median$(\Delta) = 0$), $W$ follows a known distribution. For large $n$ ($n \geq 10$), a normal approximation is used:
    \[
    Z = \frac{W - \mu_W}{\sigma_W}, \quad \mu_W = \frac{n'(n'+1)}{4}, \quad \sigma_W = \sqrt{\frac{n'(n'+1)(2n'+1)}{24}}
    \]
\end{enumerate}

\paragraph{Illustrative Example (First 10 Deltas):}

\begin{table}[t]
\centering
\caption{Wilcoxon procedure illustration (subset of data)}
\begin{tabular}{ccccc}
\toprule
$i$ & $\Delta_i$ & $|\Delta_i|$ & Rank & Signed Rank \\
\midrule
1 & -0.016 & 0.016 & 3 & -3 \\
2 & -0.003 & 0.003 & 1 & -1 \\
3 & +0.040 & 0.040 & 7 & +7 \\
4 & +0.018 & 0.018 & 4 & +4 \\
5 & +0.078 & 0.078 & 10 & +10 \\
6 & +0.038 & 0.038 & 6 & +6 \\
7 & -0.006 & 0.006 & 2 & -2 \\
8 & +0.033 & 0.033 & 5 & +5 \\
9 & +0.040 & 0.040 & 8 & +8 \\
10 & -0.027 & 0.027 & 9 & -9 \\
\midrule
\multicolumn{3}{r}{$R^+ = 7+4+10+6+5+8 = 40$} & \multicolumn{2}{l}{$R^- = 3+1+2+9 = 15$} \\
\bottomrule
\end{tabular}
\end{table}

For this subset: $W = \min(40, 15) = 15$. With $n'=10$, expected $\mu_W = 10 \cdot 11 / 4 = 27.5$, $\sigma_W \approx 9.8$, yielding $Z \approx -1.27$ (not significant at $\alpha=0.05$).

\paragraph{Full Sample Results:}

For the complete WST vs.\ AdvStats comparison ($n=168$):

\begin{itemize}
    \item $R^+ = 6543$, $R^- = 7629$
    \item $W = 6543$
    \item Expected $\mu_W = 168 \cdot 169 / 4 = 7098$
    \item $\sigma_W \approx 746.8$
    \item $Z = (6543 - 7098) / 746.8 \approx -0.74$
    \item Two-tailed $p$-value: $0.0825$
\end{itemize}

Since $p = 0.0825 > 0.05$, we fail to reject $H_0$, concluding that the median difference is not statistically significant.

For Hybrid vs.\ AdvStats:

\begin{itemize}
    \item $W = 5921$, $p = 0.0195 < 0.05$ $\Rightarrow$ reject $H_0$, significant improvement
\end{itemize}

\paragraph{Comparison with Paired $t$-Test:}

\begin{table}[h]
\centering
\caption{Wilcoxon signed-rank vs.\ paired $t$-test}
\begin{tabular}{lcc}
\toprule
Property & Wilcoxon & Paired $t$-test \\
\midrule
Distributional assumption & None (rank-based) & Normality of differences \\
Test focus & Median difference & Mean difference \\
Robustness to outliers & High & Low \\
Statistical power (normal data) & $\sim95\%$ of $t$-test & 100\% (optimal) \\
Applicability to our data & Valid (non-normal) & Invalid \\
\bottomrule
\end{tabular}
\end{table}

Given the rejection of normality (Shapiro-Wilk $p < 0.05$), the Wilcoxon test is the appropriate choice.

\subsection{Multiple Comparison Correction: Benjamini-Hochberg FDR}

When conducting $k$ simultaneous hypothesis tests, the probability of making at least one Type I error (false positive) increases. The Family-Wise Error Rate is:

\[
\text{FWER} = 1 - (1 - \alpha)^k
\]

For our $k=2$ comparisons at $\alpha = 0.05$: $\text{FWER} = 1 - 0.95^2 \approx 0.0975$ (9.75\% chance of at least one false rejection).

The Bonferroni correction controls FWER by testing each hypothesis at level $\alpha/k$, but is conservative and reduces statistical power. The Benjamini-Hochberg procedure instead controls the False Discovery Rate (FDR)—the expected proportion of false positives among all rejections—offering greater power.

\paragraph{Benjamini-Hochberg Procedure:}

\begin{enumerate}
    \item Order the $k$ raw $p$-values: $p_{(1)} \leq p_{(2)} \leq \cdots \leq p_{(k)}$
    \item For each $i = 1, \ldots, k$, compute adjusted $p$-value:
    \[
    p_{\text{FDR}}(i) = \min\left(p_{(i)} \times \frac{k}{i}, 1\right)
    \]
    \item Find the largest $i^*$ such that $p_{\text{FDR}}(i^*) \leq \alpha$
    \item Reject $H_0$ for all $j \leq i^*$
\end{enumerate}

\paragraph{Application to Our Data ($k=2$):}

\begin{table}[h]
\centering
\caption{FDR correction: worked example}
\begin{tabular}{lccccc}
\toprule
Comparison & Raw $p$ & Rank & $k/i$ & $p_{\text{FDR}}$ & Decision ($\alpha=0.05$) \\
\midrule
Hybrid vs.\ Adv & 0.0195 & 1 & 2/1 = 2.0 & $0.0195 \times 2 = 0.0390$ & Reject $H_0$ \\
WST vs.\ Adv & 0.0825 & 2 & 2/2 = 1.0 & $0.0825 \times 1 = 0.0825$ & Fail to reject \\
\bottomrule
\end{tabular}
\end{table}

The Hybrid method shows a statistically significant improvement ($p_{\text{FDR}} = 0.0390 < 0.05$), while WST does not ($p_{\text{FDR}} = 0.0825 > 0.05$).

\paragraph{Comparison with Bonferroni:}

\begin{table}[h]
\centering
\caption{Bonferroni vs.\ Benjamini-Hochberg}
\begin{tabular}{lcccc}
\toprule
Method & Controls & Threshold & Power & Our Result \\
\midrule
Bonferroni & FWER & $\alpha/k = 0.025$ & Lower & Hybrid: 0.0195 $<$ 0.025 (\checkmark) \\
 & & & & WST: 0.0825 $>$ 0.025 ($\times$) \\
Benjamini-Hochberg & FDR & Adaptive & Higher & Hybrid: 0.0390 $<$ 0.05 (\checkmark) \\
 & & & & WST: 0.0825 $>$ 0.05 ($\times$) \\
\bottomrule
\end{tabular}
\end{table}

Both methods agree on the conclusions in this case, but FDR generally provides greater power when $k$ is large.

\subsection{Effect Size: Cohen's $d$ Interpretation}

Statistical significance ($p < 0.05$) indicates that an observed difference is unlikely under the null hypothesis, but does not quantify the magnitude of the effect. Cohen's $d$ provides a standardized measure of effect size:

\[
d = \frac{\mu(\Delta)}{\sigma(\Delta)}
\]

where $\mu(\Delta)$ is the mean difference and $\sigma(\Delta)$ is the standard deviation of the differences (computed with \texttt{ddof=0} for population estimate).

\paragraph{Interpretation Thresholds:}

\begin{table}[h]
\centering
\caption{Cohen's $d$ interpretation guide with examples from our study}
\begin{tabular}{lccc}
\toprule
Range & Label & Interpretation & Our Data \\
\midrule
$|d| < 0.2$ & Small / Negligible & Minimal practical impact & WST: $d = -0.075$ \\
$0.2 \leq |d| < 0.5$ & Medium & Noticeable effect & Hybrid: $d = 0.156$ \\
$0.5 \leq |d| < 0.8$ & Medium-Large & Substantial effect & -- \\
$|d| \geq 0.8$ & Large & Major impact & -- \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Computational Implementation}

The experiments were carried out under a controlled computational setup to ensure reproducibility, scalability, and efficient execution. Table~\ref{tab:hardware_software} summarizes the hardware and software environment adopted for running the full experimental pipeline, while Table~\ref{tab:parallel} outlines the strategies used to manage computation and parallel execution.


\begin{table}[t]
\centering
\caption{Hardware and software configuration}
\label{tab:hardware_software}
\begin{tabular}{lp{9cm}}
\toprule
\textbf{Component} & \textbf{Details} \\
\midrule
CPU & Multi-core processor for Random Forest parallelization \\
GPU & NVIDIA CUDA-compatible (optional, used for WST acceleration) \\
RAM & 16 GB (sufficient for full in-memory dataset processing) \\
\midrule
Operating System & Linux (Ubuntu / WSL2) \\
Language & Python 3.12 \\
Virtual Environment & \texttt{venv} (dependency isolation) \\
\bottomrule
\end{tabular}
\end{table}


\begin{table}[t]
\centering
\caption{Parallelization strategy}
\label{tab:parallel}
\begin{tabular}{lp{9cm}}
\toprule
\textbf{Task} & \textbf{Implementation} \\
\midrule
Random Forest & \texttt{n\_jobs = -1} (uses all available CPU cores) \\
Batch execution & Sequential to ensure I/O stability \\
Cross-validation & Internally parallelized by scikit-learn \\
\bottomrule
\end{tabular}
\end{table}




\paragraph{Practical Interpretation for Our Study:}

\begin{itemize}
    \item \textbf{WST vs.\ AdvStats:} $d = -0.075$ (small negative). This corresponds to a mean difference of $-0.0106$ with $\sigma = 0.1410$, indicating that WST performs negligibly worse than AdvStats on average. The effect is not statistically significant and is practically irrelevant.

    \item \textbf{Hybrid vs.\ AdvStats:} $d = 0.156$ (small positive). With mean $+0.0171$ and $\sigma = 0.1092$, this represents a shift of approximately one-sixth of a standard deviation. While statistically significant ($p_{\text{FDR}} = 0.039$), the effect is modest in absolute terms (+1.71 percentage points in Macro-F1). Whether this justifies the increased computational cost depends on application requirements.
\end{itemize}

\paragraph{Contextualizing Effect Sizes:}

With $n=168$ paired observations, even small effects can achieve statistical significance due to high statistical power. This underscores the importance of reporting effect sizes alongside $p$-values: our findings indicate that the Hybrid method offers a real but modest advantage, which may or may not be practically meaningful depending on the operational context (see Recommendation Matrix in Section S4).


\end{document}
